The *example.gguf* file is generated by [writer.py](https://github.com/ggml-org/llama.cpp/blob/master/gguf-py/examples/writer.py) tool provided by llama.cpp.

```shell
python3 writer.py
```

The information in it can be extracted by [reader.py](https://github.com/ggml-org/llama.cpp/blob/master/gguf-py/examples/reader.py) tool, which is also from llama.cpp.

```shell
python3 reader.py example.gguf
```

The result is
```
Key-Value Pairs:
GGUF.version         : [3]
GGUF.tensor_count    : [3]
GGUF.kv_count        : [5]
general.architecture : [108 108  97 109  97]
llama.block_count    : [12]
answer               : [42]
answer_in_float      : [42.]
general.alignment    : [64]
----
Tensors:
Tensor Name                    | Shape: Shape           | Size: Size         | Quantization: Quantization
--------------------------------------------------------------------------------
tensor1                        | Shape: 32              | Size: 32           | Quantization: F32
tensor2                        | Shape: 64              | Size: 64           | Quantization: F32
tensor3                        | Shape: 96              | Size: 96           | Quantization: F32
```